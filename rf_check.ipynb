{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from data import getData, createLags, split_in_time, printMetrics, getDataBeforeMerge\n",
    "import numpy as np # linear algebra\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Predicting 36 hour ahead electricity load in Czech Republic with Random Forest \n",
    "\n",
    "#######################################################################################################################\n",
    "# Program Functionality parameters\n",
    "\n",
    "data_load = 1 \n",
    "hyperparameters_search = 0 \n",
    "prediction_length = 36\n",
    "\n",
    "#######################################################################################################################\n",
    "# Data load \n",
    "# In the thesis dataset was used generated from date = 2022-01-01 to date = '2023-07-01' with '2023-03-15 as splitting date' \n",
    "\n",
    "\n",
    "fromDate = 20210101                                 # start date for data load\n",
    "toDate = 20230701                                   # end date for data load\n",
    "location = {'CZ'}                                   # countries for data load (only 1 from CZ, HU, SK)\n",
    "load_lag = [1, 24, 48, 168]                         # lags we want to create\n",
    "\n",
    "\n",
    "X_without_lags = getData(data_load, location, fromDate, toDate)  # get data \n",
    "X_without_lags = X_without_lags.drop(columns={'time_idx', 'country', 'month_sin', 'month_cos', 'hour_cos', 'hour_sin'})\n",
    "X_without_lags = X_without_lags.set_index('timestamp')\n",
    "\n",
    "X = createLags(X_without_lags, load_lag=load_lag, get_country = False)\n",
    "\n",
    "y = X['Actual Load']\n",
    "X = X.drop(columns={'Actual Load'})\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "#######################################################################################################################\n",
    "# Train test split\n",
    "\n",
    "split_date = '2023-03-15'\n",
    "\n",
    "X_train, X_test = split_in_time(X,split_date)\n",
    "y_train, y_test = split_in_time(y,split_date)\n",
    "\n",
    "\n",
    "data_test = pd.DataFrame()\n",
    "entsoe_train, data_test = split_in_time(y, split_date)\n",
    "\n",
    "#######################################################################################################################\n",
    "# Transform data\n",
    "cat_attribs = ['day', 'weekday', 'hour', 'month']\n",
    "\n",
    "full_pipeline = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_attribs)], remainder='passthrough')\n",
    "encoder = full_pipeline.fit(X_train)\n",
    "X_train = encoder.transform(X_train)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "y_train = np.nan_to_num(y_train)\n",
    "y_test = np.nan_to_num(y_test)\n",
    "\n",
    "#######################################################################################################################\n",
    "# Hyperparameter optimization and model training\n",
    "\n",
    "if hyperparameters_search: \n",
    "    tscv = TimeSeriesSplit(n_splits = 3)\n",
    "\n",
    "    model = RandomForestRegressor()\n",
    "    parameters = {\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'max_depth' : [10, 20, 30, 40, 50, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    #gsearch = GridSearchCV(estimator=model, cv=tscv,\n",
    "    #                         param_grid=parameters,\n",
    "    #                        verbose=10)\n",
    "\n",
    "    gsearch = RandomizedSearchCV(estimator=model, cv=tscv,\n",
    "                             param_distributions=parameters,\n",
    "                             n_iter=60,\n",
    "                             verbose=10)\n",
    "\n",
    "    gsearch.fit(X_train, y_train)\n",
    "else:\n",
    "    rf = RandomForestRegressor(random_state=42,n_jobs=4,criterion =\"squared_error\",max_depth=20,max_features='auto',n_estimators=500,warm_start=True)\n",
    "    rf.fit(X_train, y_train)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################################################################################################\n",
    "# Predicting 36 hours ahead \n",
    "\n",
    "\n",
    "start_time = split_date\n",
    "end_time = X.index.max()\n",
    "df_RF =pd.DataFrame(columns={\"time\", \"prediction\", \"forecasted_time\"})\n",
    "#X_without_lags = X_without_lags.drop(columns = {'Actual Load'})\n",
    "count = 0\n",
    "\n",
    "for row in range(len(X[(X.index >= start_time) & (X.index < end_time)])):\n",
    "# for row in tqdm(range(7,10)):\n",
    "    X = X_without_lags \n",
    "\n",
    "    print('Row number ', row, ' out of ', len(X[X.index >= start_time]))\n",
    "    \n",
    "    fromPredict = X[X.index >= start_time].iloc[row]\n",
    "    fromPredictionTime = fromPredict.name\n",
    "    \n",
    "    hour = fromPredictionTime.hour\n",
    "    \n",
    "    for i in range(1, prediction_length+1): \n",
    "        count=count+1\n",
    "        \n",
    "        # create new lags\n",
    "        df = createLags(X, load_lag=load_lag, get_country= False)\n",
    "        df = df.drop(columns = {'Actual Load'})\n",
    "\n",
    "        # prediction data\n",
    "        rowToPredict = df[df.index >= start_time].iloc[row + i]\n",
    "        timeOfPrediction = rowToPredict.name\n",
    "\n",
    "        rowHelp = df[df.index >= start_time].copy()\n",
    "        rowToPredict = rowHelp.iloc[[row + i]]\n",
    "\n",
    "        #transform data for xgboost\n",
    "        rowToPredictEncode = encoder.transform(rowToPredict)\n",
    "        \n",
    "        # make prediction\n",
    "        prediction = rf.predict(rowToPredictEncode)\n",
    "        \n",
    "        # update X df and store prediction\n",
    "        X.loc[X[X.index >= start_time].index[row + i],'Actual Load'] = prediction\n",
    "        \n",
    "        df_RF.loc[count - 1, 'time'] = fromPredictionTime\n",
    "        df_RF.loc[count - 1, 'prediction'] = prediction[0]\n",
    "        df_RF.loc[count - 1, 'forecasted_time'] = timeOfPrediction\n",
    "        #print('Prediction from ', fromPredictionTime, ' load predicted ', prediction[0][0], ' time of load', timeOfPrediction)\n",
    "\n",
    "print('done') \n",
    "\n",
    "df_RF.to_csv('RF.csv')\n",
    "rf_results = pd.merge(df_RF, X[\"Actual Load\"], how='left', left_on='forecasted_time', right_on = 'timestamp')\n",
    "#######################################################################################################################\n",
    "# Results \n",
    "\n",
    "printMetrics(rf_results)  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
